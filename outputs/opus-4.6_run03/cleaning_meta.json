{
  "n_models_raw": 83,
  "n_benchmarks_raw": 49,
  "n_models_filtered": 74,
  "n_benchmarks_filtered": 40,
  "missing_fraction_raw": 0.6619129579542661,
  "missing_fraction_filtered": 0.5658783783783784,
  "min_bench_obs_threshold": 8,
  "min_model_obs_threshold": 8,
  "benchmarks_dropped": [
    "AA Long Context Reasoning",
    "AIME 2026",
    "BigCodeBench",
    "GDP-Val AA",
    "IFBench",
    "IMO 2025",
    "MathVision",
    "SciCode",
    "SimpleBench"
  ],
  "models_dropped": [
    "Amazon Nova Premier",
    "Amazon Nova Pro",
    "Codestral 25.01",
    "DeepSeek-R1-Distill-Qwen-14B",
    "DeepSeek-R1-Distill-Qwen-32B",
    "DeepSeek-R1-Distill-Qwen-7B",
    "Devstral 2",
    "GPT-4.1 nano",
    "Phi-4-reasoning"
  ],
  "normalization": "min-max to 0-100 per benchmark",
  "imputation": "column mean (for rank analysis only)",
  "benchmarks_used": [
    "AA Intelligence Index",
    "AIME 2024",
    "AIME 2025",
    "ARC-AGI-1",
    "ARC-AGI-2",
    "Arena-Hard Auto",
    "BrowseComp",
    "BRUMO 2025",
    "Chatbot Arena Elo",
    "CMIMC 2025",
    "Codeforces Rating",
    "CritPt",
    "FrontierMath",
    "GPQA Diamond",
    "GSM8K",
    "HLE (Humanity's Last Exam)",
    "HMMT Feb 2025",
    "HMMT Nov 2025",
    "HumanEval",
    "IFEval",
    "LiveBench",
    "LiveCodeBench",
    "MATH-500",
    "MathArena Apex 2025",
    "MMLU",
    "MMLU-Pro",
    "MMMU",
    "MMMU-Pro",
    "MRCR v2",
    "OSWorld",
    "SimpleQA",
    "SMT 2025",
    "SWE-bench Pro",
    "SWE-bench Verified",
    "Tau-Bench Retail",
    "Tau-Bench Telecom",
    "Terminal-Bench 2.0",
    "Terminal-Bench 1.0",
    "USAMO 2025",
    "Video-MMU"
  ]
}