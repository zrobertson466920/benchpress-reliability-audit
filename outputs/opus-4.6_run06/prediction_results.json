{
  "method": "Ridge regression (alpha=1.0) from selected benchmark subset",
  "overall_mae": 8.170071015659966,
  "per_benchmark_mae": {
    "AIME 2025": 13.149509607571801,
    "ARC-AGI-1": 9.79551982855185,
    "Arena-Hard Auto": 13.709308016954463,
    "BrowseComp": 7.168167702178496,
    "BRUMO 2025": 5.768541106220837,
    "Chatbot Arena Elo": 8.646929399907927,
    "CMIMC 2025": 6.723135925159168,
    "Codeforces Rating": 12.610624796975609,
    "CritPt": 6.047215142647583,
    "FrontierMath": 9.043218597932446,
    "GPQA Diamond": 10.688292774194409,
    "GSM8K": 5.503355259697751,
    "HLE (Humanity's Last Exam)": 8.922194834587065,
    "HMMT Nov 2025": 3.3259619107518836,
    "HumanEval": 9.539112511975624,
    "IFEval": 8.023963420927977,
    "LiveBench": 6.2281940775036615,
    "LiveCodeBench": 10.50213615287492,
    "MATH-500": 6.701874580431644,
    "MathArena Apex 2025": 6.766079045583103,
    "MMLU": 7.502659440753149,
    "MMMU": 10.537823980428056,
    "MMMU-Pro": 4.544586160477456,
    "OSWorld": 7.939552306388839,
    "SimpleQA": 11.70835021067314,
    "SMT 2025": 6.023260229534115,
    "SWE-bench Pro": 7.507696432527132,
    "Tau-Bench Retail": 4.300726253091061,
    "Terminal-Bench 2.0": 7.546946035245677,
    "Terminal-Bench 1.0": 8.627194728052128
  },
  "evaluation_protocol": "leave-one-out cross-validation on cleaned normalized matrix",
  "n_predictor_benchmarks": 5,
  "achieves_mae_under_5": false,
  "predictor_benchmarks": [
    "MMLU-Pro",
    "ARC-AGI-2",
    "HMMT Feb 2025",
    "SWE-bench Verified",
    "AIME 2024"
  ],
  "normalization": "min-max 0-100 per benchmark",
  "note": "MAE is on 0-100 normalized scale"
}