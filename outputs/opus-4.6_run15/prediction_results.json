{
  "method": "ridge_regression_all_other_benchmarks_to_target",
  "overall_mae": 12.150725488299326,
  "per_benchmark_mae": {
    "AIME 2024": 9.981197736627676,
    "AIME 2025": 11.360091003140115,
    "ARC-AGI-1": 23.84908199982358,
    "ARC-AGI-2": 11.840742335650836,
    "Arena-Hard Auto": 8.471496533454083,
    "BrowseComp": 8.622740749581066,
    "BRUMO 2025": 8.633915929589065,
    "Chatbot Arena Elo": 14.21091784615406,
    "CMIMC 2025": 10.50650141704911,
    "Codeforces Rating": 12.901873250084192,
    "CritPt": 8.849152698139557,
    "FrontierMath": 16.674745885814612,
    "GPQA Diamond": 14.099724297530791,
    "GSM8K": 4.357081944201782,
    "HLE (Humanity's Last Exam)": 22.16037380117701,
    "HMMT Feb 2025": 10.923422304487048,
    "HMMT Nov 2025": 7.682917886586565,
    "HumanEval": 8.514038301863605,
    "IFEval": 12.601278103183311,
    "LiveBench": 4.74362752670941,
    "LiveCodeBench": 12.715902219573087,
    "MATH-500": 10.007522046639755,
    "MathArena Apex 2025": 11.274497611000204,
    "MMLU": 10.990213781833907,
    "MMLU-Pro": 9.234715863701503,
    "MMMU": 11.83644614260469,
    "MMMU-Pro": 30.63724714782042,
    "OSWorld": 13.350942561264572,
    "SimpleQA": 12.219069207815037,
    "SMT 2025": 17.27171495850199,
    "SWE-bench Pro": 11.502676316211275,
    "SWE-bench Verified": 14.433013109470041,
    "Tau-Bench Retail": 9.723338573503346,
    "Terminal-Bench 2.0": 9.613507570821625,
    "Terminal-Bench 1.0": 10.99167570223794
  },
  "evaluation_protocol": "5-fold CV on min-max normalized imputed (rank-4) matrix, scored on observed entries only",
  "n_predictor_benchmarks": 34,
  "achieves_mae_under_5": false,
  "normalization": "min-max to [0,100] per benchmark",
  "imputation_method": "iterative SVD rank-4"
}