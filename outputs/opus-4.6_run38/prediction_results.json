{
  "method": "Ridge regression from selected benchmark subset",
  "overall_mae": 8.686785229046661,
  "per_benchmark_mae": {
    "AIME 2024": 1.0760530429815347,
    "ARC-AGI-1": 14.238547254597055,
    "ARC-AGI-2": 22.1187383149253,
    "Arena-Hard Auto": null,
    "Chatbot Arena Elo": 21.329759834541193,
    "CMIMC 2025": 2.316688697218615,
    "Codeforces Rating": 12.095944656336192,
    "CritPt": 19.41902223333663,
    "FrontierMath": 6.048388086633966,
    "GPQA Diamond": 2.579338880716338,
    "GSM8K": null,
    "HLE (Humanity's Last Exam)": 5.168848200145216,
    "HMMT Feb 2025": 6.032137698553352,
    "HumanEval": 2.5914999026416723,
    "IFEval": 3.299630999669489,
    "LiveBench": 2.3707900921418363,
    "LiveCodeBench": 7.875921055421122,
    "MATH-500": 1.7875925333126723,
    "MathArena Apex 2025": 8.180286682916403,
    "MMLU-Pro": 2.4294728483229306,
    "MMMU-Pro": 7.079621129676891,
    "OSWorld": 24.309232578747835,
    "SimpleQA": 12.983497977363346,
    "SMT 2025": 1.6366636624807227,
    "SWE-bench Verified": 5.174997442265939,
    "Tau-Bench Retail": 17.729089863397714,
    "Terminal-Bench 1.0": null
  },
  "evaluation_protocol": "Leave-one-out cross-validation per target benchmark (normalized 0-100 scale)",
  "n_predictor_benchmarks": 8,
  "achieves_mae_under_5": false
}