model_id,model_name,benchmark_id,benchmark_name,y_pred
claude-opus-4,Claude Opus 4,aime_2024,AIME 2024,75.50000000000001
claude-opus-4,Claude Opus 4,aime_2025,AIME 2025,90.0
claude-opus-4,Claude Opus 4,arc_agi_1,ARC-AGI-1,35.70000000000001
claude-opus-4,Claude Opus 4,arc_agi_2,ARC-AGI-2,8.6
claude-opus-4,Claude Opus 4,codeforces_rating,Codeforces Rating,1886.0
claude-opus-4,Claude Opus 4,critpt,CritPt,0.3
claude-opus-4,Claude Opus 4,frontiermath,FrontierMath,10.0
claude-opus-4,Claude Opus 4,gpqa_diamond,GPQA Diamond,83.3
claude-opus-4,Claude Opus 4,hle,HLE (Humanity's Last Exam),7.1
claude-opus-4,Claude Opus 4,hmmt_2025,HMMT Feb 2025,15.9
claude-opus-4,Claude Opus 4,ifeval,IFEval,89.69999999999999
claude-opus-4,Claude Opus 4,livecodebench,LiveCodeBench,47.39999999999999
claude-opus-4,Claude Opus 4,math_500,MATH-500,94.4
claude-opus-4,Claude Opus 4,mmlu,MMLU,88.8
claude-opus-4,Claude Opus 4,mmmu,MMMU,76.5
claude-opus-4,Claude Opus 4,simpleqa,SimpleQA,22.8
claude-opus-4,Claude Opus 4,swe_bench_pro,SWE-bench Pro,35.8
claude-opus-4,Claude Opus 4,tau_bench_retail,Tau-Bench Retail,81.4
claude-opus-4,Claude Opus 4,terminal_bench,Terminal-Bench 2.0,43.2
claude-opus-4.1,Claude Opus 4.1,frontiermath,FrontierMath,3.2350000000000003
claude-opus-4.1,Claude Opus 4.1,gpqa_diamond,GPQA Diamond,70.62245731445634
claude-opus-4.1,Claude Opus 4.1,hle,HLE (Humanity's Last Exam),2.415919369952075
claude-opus-4.1,Claude Opus 4.1,humaneval,HumanEval,81.85661821360779
claude-opus-4.1,Claude Opus 4.1,mmlu,MMLU,89.33778530700857
claude-opus-4.1,Claude Opus 4.1,mmlu_pro,MMLU-Pro,86.88952290602283
claude-opus-4.1,Claude Opus 4.1,simpleqa,SimpleQA,22.83508108750599
claude-opus-4.1,Claude Opus 4.1,swe_bench_pro,SWE-bench Pro,46.93619022467664
claude-opus-4.1,Claude Opus 4.1,terminal_bench,Terminal-Bench 2.0,13.56643916220444
claude-opus-4.1,Claude Opus 4.1,terminal_bench_1,Terminal-Bench 1.0,43.8
deepseek-r1-0528,DeepSeek-R1-0528,aime_2024,AIME 2024,91.74081949286801
deepseek-r1-0528,DeepSeek-R1-0528,aime_2025,AIME 2025,88.43620574553847
deepseek-r1-0528,DeepSeek-R1-0528,arc_agi_1,ARC-AGI-1,29.00318336851353
deepseek-r1-0528,DeepSeek-R1-0528,brumo_2025,BRUMO 2025,90.97281825614927
deepseek-r1-0528,DeepSeek-R1-0528,codeforces_rating,Codeforces Rating,2001.7533832813276
deepseek-r1-0528,DeepSeek-R1-0528,gpqa_diamond,GPQA Diamond,82.02092677688333
deepseek-r1-0528,DeepSeek-R1-0528,hle,HLE (Humanity's Last Exam),19.984613720582225
deepseek-r1-0528,DeepSeek-R1-0528,humaneval,HumanEval,86.64531635130263
deepseek-r1-0528,DeepSeek-R1-0528,ifeval,IFEval,82.8136763118228
deepseek-r1-0528,DeepSeek-R1-0528,imo_2025,IMO 2025,6.85
deepseek-r1-0528,DeepSeek-R1-0528,livecodebench,LiveCodeBench,74.43093044678076
deepseek-r1-0528,DeepSeek-R1-0528,math_500,MATH-500,97.89677062278757
deepseek-r1-0528,DeepSeek-R1-0528,matharena_apex_2025,MathArena Apex 2025,-1.675
deepseek-r1-0528,DeepSeek-R1-0528,mmlu,MMLU,90.14066719950274
deepseek-r1-0528,DeepSeek-R1-0528,mmlu_pro,MMLU-Pro,84.88421317306646
deepseek-r1-0528,DeepSeek-R1-0528,simpleqa,SimpleQA,33.66941562766627
deepseek-r1-0528,DeepSeek-R1-0528,smt_2025,SMT 2025,84.46272576927558
deepseek-r1-0528,DeepSeek-R1-0528,swe_bench_verified,SWE-bench Verified,60.587591397659736
deepseek-r1-0528,DeepSeek-R1-0528,usamo_2025,USAMO 2025,30.059999999999995
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,aime_2024,AIME 2024,98.92805665371856
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,aime_2025,AIME 2025,94.63855418353468
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,browsecomp,BrowseComp,76.99220492163468
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,gpqa_diamond,GPQA Diamond,90.4582535757825
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,hle,HLE (Humanity's Last Exam),41.57161662617376
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,ifeval,IFEval,88.24449851489311
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,mathvision,MathVision,88.8
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,mmlu,MMLU,89.16900656963476
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,mmmu,MMMU,85.7141454293156
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,swe_bench_verified,SWE-bench Verified,77.13321131209685
doubao-seed-2.0-pro,Doubao Seed 2.0 Pro,terminal_bench,Terminal-Bench 2.0,55.282263579065805
gemini-2.5-pro,Gemini 2.5 Pro,aa_intelligence_index,AA Intelligence Index,70.0
gemini-2.5-pro,Gemini 2.5 Pro,aime_2024,AIME 2024,92.0
gemini-2.5-pro,Gemini 2.5 Pro,aime_2025,AIME 2025,86.7
gemini-2.5-pro,Gemini 2.5 Pro,arc_agi_1,ARC-AGI-1,41.0
gemini-2.5-pro,Gemini 2.5 Pro,arc_agi_2,ARC-AGI-2,4.9
gemini-2.5-pro,Gemini 2.5 Pro,arena_hard,Arena-Hard Auto,90.8
gemini-2.5-pro,Gemini 2.5 Pro,brumo_2025,BRUMO 2025,90.0
gemini-2.5-pro,Gemini 2.5 Pro,chatbot_arena_elo,Chatbot Arena Elo,1437.0
gemini-2.5-pro,Gemini 2.5 Pro,codeforces_rating,Codeforces Rating,2001.0
gemini-2.5-pro,Gemini 2.5 Pro,critpt,CritPt,2.0
gemini-2.5-pro,Gemini 2.5 Pro,frontiermath,FrontierMath,5.0
gemini-2.5-pro,Gemini 2.5 Pro,gpqa_diamond,GPQA Diamond,84.0
gemini-2.5-pro,Gemini 2.5 Pro,hle,HLE (Humanity's Last Exam),18.8
gemini-2.5-pro,Gemini 2.5 Pro,hmmt_2025,HMMT Feb 2025,82.5
gemini-2.5-pro,Gemini 2.5 Pro,hmmt_nov_2025,HMMT Nov 2025,66.67
gemini-2.5-pro,Gemini 2.5 Pro,imo_2025,IMO 2025,31.549999999999997
gemini-2.5-pro,Gemini 2.5 Pro,livebench,LiveBench,58.3
gemini-2.5-pro,Gemini 2.5 Pro,math_500,MATH-500,97.3
gemini-2.5-pro,Gemini 2.5 Pro,matharena_apex_2025,MathArena Apex 2025,0.5
gemini-2.5-pro,Gemini 2.5 Pro,mmlu,MMLU,89.8
gemini-2.5-pro,Gemini 2.5 Pro,mmlu_pro,MMLU-Pro,85.6
gemini-2.5-pro,Gemini 2.5 Pro,mmmu,MMMU,81.7
gemini-2.5-pro,Gemini 2.5 Pro,mrcr_v2,MRCR v2,83.1
gemini-2.5-pro,Gemini 2.5 Pro,simplebench,SimpleBench,62.4
gemini-2.5-pro,Gemini 2.5 Pro,simpleqa,SimpleQA,52.900000000000006
gemini-2.5-pro,Gemini 2.5 Pro,smt_2025,SMT 2025,84.91
gemini-2.5-pro,Gemini 2.5 Pro,swe_bench_verified,SWE-bench Verified,63.8
gemini-2.5-pro,Gemini 2.5 Pro,terminal_bench_1,Terminal-Bench 1.0,25.3
gemini-2.5-pro,Gemini 2.5 Pro,usamo_2025,USAMO 2025,24.0
gemini-2.5-pro,Gemini 2.5 Pro,video_mmu,Video-MMU,84.8
gpt-4.1,GPT-4.1,aime_2025,AIME 2025,49.27287046681772
gpt-4.1,GPT-4.1,arc_agi_1,ARC-AGI-1,-4.7
gpt-4.1,GPT-4.1,arena_hard,Arena-Hard Auto,61.5
gpt-4.1,GPT-4.1,codeforces_rating,Codeforces Rating,1008.3230802110945
gpt-4.1,GPT-4.1,hle,HLE (Humanity's Last Exam),1.375
gpt-4.1,GPT-4.1,hmmt_2025,HMMT Feb 2025,32.38889001475682
gpt-4.1,GPT-4.1,humaneval,HumanEval,88.16526691749067
gpt-4.1,GPT-4.1,ifeval,IFEval,81.13680804740417
gpt-4.1,GPT-4.1,livecodebench,LiveCodeBench,44.376146755080256
gpt-4.1,GPT-4.1,math_500,MATH-500,91.95947522032344
gpt-4.1,GPT-4.1,mmlu,MMLU,92.69921808434421
gpt-4.1,GPT-4.1,mmmu,MMMU,70.77838290036432
gpt-4.1,GPT-4.1,simpleqa,SimpleQA,42.33844614435206
gpt-4.1,GPT-4.1,swe_bench_verified,SWE-bench Verified,49.41023187093494
gpt-4.1,GPT-4.1,terminal_bench_1,Terminal-Bench 1.0,30.3
grok-3-beta,Grok 3 Beta,aime_2024,AIME 2024,101.44795905776613
grok-3-beta,Grok 3 Beta,aime_2025,AIME 2025,93.7650535213614
grok-3-beta,Grok 3 Beta,arc_agi_1,ARC-AGI-1,27.394862824672717
grok-3-beta,Grok 3 Beta,chatbot_arena_elo,Chatbot Arena Elo,1447.861305378138
grok-3-beta,Grok 3 Beta,hle,HLE (Humanity's Last Exam),20.567755693982715
grok-3-beta,Grok 3 Beta,humaneval,HumanEval,89.75481262019076
grok-3-beta,Grok 3 Beta,ifeval,IFEval,87.3081033938999
grok-3-beta,Grok 3 Beta,mmlu_pro,MMLU-Pro,80.88620021937706
grok-3-beta,Grok 3 Beta,simpleqa,SimpleQA,28.89074614456595
grok-3-beta,Grok 3 Beta,swe_bench_verified,SWE-bench Verified,62.60617238099647
grok-4,Grok 4,aa_intelligence_index,AA Intelligence Index,73.0
grok-4,Grok 4,aa_lcr,AA Long Context Reasoning,68.68362879856242
grok-4,Grok 4,aime_2024,AIME 2024,94.65821483763108
grok-4,Grok 4,arc_agi_2,ARC-AGI-2,18.350974630313132
grok-4,Grok 4,brumo_2025,BRUMO 2025,95.5209743385844
grok-4,Grok 4,chatbot_arena_elo,Chatbot Arena Elo,1428.7686489669231
grok-4,Grok 4,cmimc_2025,CMIMC 2025,81.02811803761703
grok-4,Grok 4,codeforces_rating,Codeforces Rating,2411.1855148587483
grok-4,Grok 4,frontiermath,FrontierMath,16.188684108849607
grok-4,Grok 4,gpqa_diamond,GPQA Diamond,87.72194704908695
grok-4,Grok 4,hle,HLE (Humanity's Last Exam),26.99318082950469
grok-4,Grok 4,hmmt_nov_2025,HMMT Nov 2025,90.18459402800468
grok-4,Grok 4,ifeval,IFEval,89.11838897948786
grok-4,Grok 4,imo_2025,IMO 2025,17.63078206447659
grok-4,Grok 4,livecodebench,LiveCodeBench,76.86806409035879
grok-4,Grok 4,matharena_apex_2025,MathArena Apex 2025,7.878912364771816
grok-4,Grok 4,mmlu,MMLU,91.32820287078968
grok-4,Grok 4,mmlu_pro,MMLU-Pro,87.25440293544727
grok-4,Grok 4,mmmu,MMMU,77.82517547819049
grok-4,Grok 4,mmmu_pro,MMMU-Pro,62.76262917032376
grok-4,Grok 4,osworld,OSWorld,51.16050007991136
grok-4,Grok 4,simpleqa,SimpleQA,50.95851028085015
grok-4,Grok 4,smt_2025,SMT 2025,86.96313366240858
grok-4,Grok 4,swe_bench_pro,SWE-bench Pro,45.17093147159055
grok-4,Grok 4,swe_bench_verified,SWE-bench Verified,74.90254811730023
grok-4,Grok 4,terminal_bench,Terminal-Bench 2.0,33.451572073142906
grok-4,Grok 4,terminal_bench_1,Terminal-Bench 1.0,38.4125027313235
grok-4,Grok 4,usamo_2025,USAMO 2025,54.92041975413555
kimi-k2,Kimi K2,aime_2024,AIME 2024,72.20310206257415
kimi-k2,Kimi K2,aime_2025,AIME 2025,63.92292048810492
kimi-k2,Kimi K2,arena_hard,Arena-Hard Auto,54.5
kimi-k2,Kimi K2,gpqa_diamond,GPQA Diamond,80.16066532272242
kimi-k2,Kimi K2,hle,HLE (Humanity's Last Exam),8.970777789058964
kimi-k2,Kimi K2,hmmt_2025,HMMT Feb 2025,49.56174283731227
kimi-k2,Kimi K2,ifeval,IFEval,87.14189152933209
kimi-k2,Kimi K2,livecodebench,LiveCodeBench,68.75250426677276
kimi-k2,Kimi K2,math_500,MATH-500,99.79550472914191
kimi-k2,Kimi K2,mmlu_pro,MMLU-Pro,90.12348018334934
kimi-k2,Kimi K2,osworld,OSWorld,36.32508036357978
kimi-k2,Kimi K2,simpleqa,SimpleQA,37.35280501550011
kimi-k2,Kimi K2,swe_bench_verified,SWE-bench Verified,66.45235974373918
llama-4-maverick,Llama 4 Maverick,arc_agi_1,ARC-AGI-1,6.112707303831882
llama-4-maverick,Llama 4 Maverick,bigcodebench,BigCodeBench,49.91067098195074
llama-4-maverick,Llama 4 Maverick,chatbot_arena_elo,Chatbot Arena Elo,1404.520276266925
llama-4-maverick,Llama 4 Maverick,gpqa_diamond,GPQA Diamond,68.92166208455453
llama-4-maverick,Llama 4 Maverick,humaneval,HumanEval,85.94620304501966
llama-4-maverick,Llama 4 Maverick,livecodebench,LiveCodeBench,46.91028329189302
llama-4-maverick,Llama 4 Maverick,math_500,MATH-500,88.94871485049505
llama-4-maverick,Llama 4 Maverick,mmmu,MMMU,73.56223823831589
llama-4-maverick,Llama 4 Maverick,simpleqa,SimpleQA,27.432262721876363
llama-4-maverick,Llama 4 Maverick,swe_bench_verified,SWE-bench Verified,48.226700666760735
llama-4-maverick,Llama 4 Maverick,terminal_bench_1,Terminal-Bench 1.0,15.47223579954666
minimax-m2,MiniMax-M2,aime_2024,AIME 2024,65.0
minimax-m2,MiniMax-M2,aime_2025,AIME 2025,78.29999999999998
minimax-m2,MiniMax-M2,chatbot_arena_elo,Chatbot Arena Elo,1408.0
minimax-m2,MiniMax-M2,gpqa_diamond,GPQA Diamond,78.0
minimax-m2,MiniMax-M2,hle,HLE (Humanity's Last Exam),12.5
minimax-m2,MiniMax-M2,humaneval,HumanEval,90.0
minimax-m2,MiniMax-M2,ifeval,IFEval,88.0
minimax-m2,MiniMax-M2,math_500,MATH-500,97.0
minimax-m2,MiniMax-M2,mmlu,MMLU,87.0
minimax-m2,MiniMax-M2,mmlu_pro,MMLU-Pro,82.0
minimax-m2,MiniMax-M2,mmmu,MMMU,75.0
minimax-m2,MiniMax-M2,simpleqa,SimpleQA,40.0
minimax-m2,MiniMax-M2,swe_bench_pro,SWE-bench Pro,32.0
minimax-m2,MiniMax-M2,swe_bench_verified,SWE-bench Verified,69.4
minimax-m2,MiniMax-M2,terminal_bench,Terminal-Bench 2.0,30.0
o3-mini-high,o3-mini (high),aime_2024,AIME 2024,87.25932679680946
o3-mini-high,o3-mini (high),arc_agi_1,ARC-AGI-1,43.09247312587639
o3-mini-high,o3-mini (high),arc_agi_2,ARC-AGI-2,16.366437053701585
o3-mini-high,o3-mini (high),arena_hard,Arena-Hard Auto,68.29718198333256
o3-mini-high,o3-mini (high),chatbot_arena_elo,Chatbot Arena Elo,1403.653304371823
o3-mini-high,o3-mini (high),frontiermath,FrontierMath,15.120500737380139
o3-mini-high,o3-mini (high),hle,HLE (Humanity's Last Exam),19.232183468565506
o3-mini-high,o3-mini (high),hmmt_2025,HMMT Feb 2025,67.9985732063214
o3-mini-high,o3-mini (high),humaneval,HumanEval,92.16981606319644
o3-mini-high,o3-mini (high),ifeval,IFEval,87.82377660529073
o3-mini-high,o3-mini (high),livecodebench,LiveCodeBench,72.4472703665261
o3-mini-high,o3-mini (high),math_500,MATH-500,96.64393485974067
o3-mini-high,o3-mini (high),simpleqa,SimpleQA,29.53658909235372
o3-mini-high,o3-mini (high),swe_bench_verified,SWE-bench Verified,59.51324861679373
o3-mini-high,o3-mini (high),usamo_2025,USAMO 2025,1.259955476356426
