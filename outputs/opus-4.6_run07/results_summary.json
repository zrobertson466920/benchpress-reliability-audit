{
  "data_discovery": {
    "raw_schema": "JSON with top-level keys: models (list of 83 dicts with id/name/provider/release_date/params_total_M/params_active_M/architecture/is_reasoning/open_weights), benchmarks (list of 49 dicts with id/name/category/metric/num_problems/source_url), scores (list of 1390 dicts with model_id/benchmark_id/score/reference_url), generated (timestamp string).",
    "extraction_decisions": "Built 83x49 matrix indexed by model_id x benchmark_id. 15 duplicate (model_id, benchmark_id) pairs (all deepseek-r1-distill variants) resolved by simple averaging per canonical_evaluation.md. All 83 models and 49 benchmarks retained in raw performance matrix.",
    "n_models_raw": 83,
    "n_benchmarks_raw": 49
  },
  "data": {
    "n_models": 74,
    "n_benchmarks": 35,
    "missing_fraction": 0.5193050193050193,
    "preprocessing": "Two paths: (A) Full 83x49 matrix with per-benchmark min-max normalization to [0,100], completed via iterative truncated SVD at rank 5. (B) Filtered matrix (74x35 with >=10/>=8 coverage), z-score normalized per benchmark, mean-imputed. Scale mismatch handled: benchmarks span Elo ratings (~800-3000), percentages (0-100), and index scores.",
    "benchmarks_used": [
      "AIME 2024",
      "AIME 2025",
      "ARC-AGI-1",
      "ARC-AGI-2",
      "Arena-Hard Auto",
      "BrowseComp",
      "BRUMO 2025",
      "Chatbot Arena Elo",
      "CMIMC 2025",
      "Codeforces Rating",
      "CritPt",
      "FrontierMath",
      "GPQA Diamond",
      "GSM8K",
      "HLE (Humanity's Last Exam)",
      "HMMT Feb 2025",
      "HMMT Nov 2025",
      "HumanEval",
      "IFEval",
      "LiveBench",
      "LiveCodeBench",
      "MATH-500",
      "MathArena Apex 2025",
      "MMLU",
      "MMLU-Pro",
      "MMMU",
      "MMMU-Pro",
      "OSWorld",
      "SimpleQA",
      "SMT 2025",
      "SWE-bench Pro",
      "SWE-bench Verified",
      "Tau-Bench Retail",
      "Terminal-Bench 2.0",
      "Terminal-Bench 1.0"
    ]
  },
  "rank_analysis": {
    "method": "SVD on z-scored mean-imputed filtered matrix (primary); cross-validated rank from iterative SVD completion on full normalized matrix",
    "effective_rank": 5,
    "variance_explained_by_rank": 0.6994140259029807,
    "singular_values": [
      21.760159952324077,
      13.598449981914413,
      8.635687089246325,
      8.03149450217436,
      6.984881734103797,
      6.426804828028592,
      6.088492332742628,
      5.665289330513222,
      5.331071793060086,
      4.968830718904712,
      4.615743968666412,
      4.320528402028922,
      4.220042667154946,
      3.91638369023138,
      3.8700324898217344
    ],
    "justification": "Cross-validated rank selection yields rank 5 (validation MAE 14.9 on 0-100 scale). On the filtered z-scored matrix, the first component explains 39.1% (dominant general capability factor), with 69.9% at rank 5. The 80% threshold requires rank 9, 90% requires rank 15. The matrix is moderately low-rank: a handful of components capture meaningful structure, but the long tail reflects genuine benchmark-specific variance and noise from imputing ~52% missing entries."
  },
  "benchmark_selection": {
    "method": "Greedy forward selection minimizing ridge regression MAE on z-scored filtered imputed matrix",
    "selected_benchmarks": [
      "MMLU-Pro",
      "ARC-AGI-2",
      "IFEval",
      "HMMT Feb 2025",
      "MATH-500",
      "SWE-bench Verified",
      "HumanEval"
    ],
    "n_selected": 7,
    "selection_criterion": "Minimize mean absolute prediction error of ridge from selected subset to all remaining benchmarks in z-score space"
  },
  "prediction": {
    "method": "Hybrid: iterative SVD completion blended with ridge regression from revealed benchmarks in normalized space (canonical); ridge from selected subset (own eval)",
    "overall_mae": 23.119492015628545,
    "per_benchmark_mae": {
      "AIME 2024": 4.95493633456495,
      "AIME 2025": 11.253301254288427,
      "ARC-AGI-1": 15.193164465985877,
      "Arena-Hard Auto": 28.525783388486445,
      "BrowseComp": 9.026094194863884,
      "BRUMO 2025": 2.419365116692319,
      "Chatbot Arena Elo": 26.064434162859342,
      "CMIMC 2025": 7.361423561571368,
      "Codeforces Rating": 272.0869721439619,
      "CritPt": 2.2097117569971436,
      "FrontierMath": 5.108989313426579,
      "GPQA Diamond": 4.817767942962858,
      "HLE (Humanity's Last Exam)": 5.283869679818157,
      "LiveCodeBench": 3.8043880798465763,
      "MathArena Apex 2025": 13.942600618047617,
      "MMLU": 3.0965813405701885,
      "MMMU": 2.1816874727574103,
      "MMMU-Pro": 10.460409996293427,
      "OSWorld": 20.134600104717997,
      "SimpleQA": 11.392486666578716,
      "SMT 2025": 4.86113608054298,
      "SWE-bench Pro": 4.415952558653969,
      "Terminal-Bench 2.0": 9.225464656325952,
      "Terminal-Bench 1.0": 10.711026069272856
    },
    "evaluation_protocol": "Own: LOO-model CV with ridge on raw-scale filtered matrix. Canonical: hybrid SVD+ridge blend in 0-100 normalized space.",
    "n_predictor_benchmarks": 7,
    "achieves_mae_under_5": false
  },
  "canonical_evaluation": {
    "canonical_overall_mae_normalized": 5.679056035871334,
    "canonical_median_ae_normalized": 1.3356457966140738,
    "canonical_coverage": 1.0,
    "n_predicted": 196,
    "n_total_pairs": 196,
    "method_note": "Hybrid: (A) global iterative SVD completion at rank 5 on full 83x49 normalized matrix; (B) per-target ridge regression from 5 revealed benchmarks in normalized space; blended with adaptive weights based on training sample size. Predictions clipped to [-5, 105] in normalized space."
  },
  "methodology_notes": "Pipeline: (1) Extract full 83x49 raw matrix; average 15 duplicates. (2) Two preprocessing paths: (A) min-max normalize to 0-100, complete via iterative SVD at rank 5 (CV-selected, MAE=14.9); (B) filter to 35 benchmarks (>=10 coverage) and 74 models (>=8 coverage), z-score, mean-impute. (3) SVD on filtered matrix reveals moderate low-rank structure: first component dominant at 39.1% but long tail significant \u2014 80% variance needs rank 9. (4) Greedy forward selection of 7 benchmarks. (5) Canonical predictions via hybrid SVD+ridge blend in normalized space. Key challenges: 66% missingness, scale mismatch, low coverage on niche benchmarks. The dominant rank-1 factor captures overall model capability; subsequent factors differentiate domains (math/coding/reasoning)."
}