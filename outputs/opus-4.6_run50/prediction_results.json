{
  "method": "Ridge regression (alpha=1.0) from selected benchmark subset",
  "overall_mae": 20.9221,
  "per_benchmark_mae": {
    "MMLU": 4.1428,
    "MMLU-Pro": 5.6347,
    "MATH-500": 4.038,
    "FrontierMath": 7.4255,
    "HLE (Humanity's Last Exam)": 6.272,
    "ARC-AGI-2": 9.992,
    "BrowseComp": 6.5563,
    "SimpleQA": 10.9377,
    "IFEval": 4.205,
    "HumanEval": 5.5401,
    "Codeforces Rating": 266.6205,
    "OSWorld": 8.1039,
    "MMMU": 3.2223,
    "MMMU-Pro": 4.5526,
    "Arena-Hard Auto": 20.0631,
    "Chatbot Arena Elo": 25.6903,
    "SWE-bench Pro": 5.9282,
    "AIME 2024": 9.4523,
    "HMMT Feb 2025": 7.9759,
    "CritPt": 4.027,
    "GSM8K": 3.882,
    "Terminal-Bench 1.0": 11.4299,
    "ARC-AGI-1": 11.9721,
    "BRUMO 2025": 4.6276,
    "SMT 2025": 3.8334,
    "HMMT Nov 2025": 4.1454,
    "CMIMC 2025": 7.0604,
    "MathArena Apex 2025": 4.7601,
    "LiveBench": 7.0224
  },
  "evaluation_protocol": "5-fold CV on observed entries (raw scores)",
  "n_predictor_benchmarks": 6,
  "achieves_mae_under_5": false
}