{
  "data_discovery": {
    "raw_schema": "JSON with top-level keys: 'models' (list of 83 model objects with id/name/provider/params/architecture/is_reasoning/open_weights), 'benchmarks' (list of 49 benchmark objects with id/name/category/metric/num_problems/source_url), 'scores' (list of 1390 score entries with model_id/benchmark_id/score/reference_url), 'generated' (timestamp string).",
    "extraction_decisions": "Mapped scores to (model_id, benchmark_id) pairs. Found 15 duplicate pairs (mostly DeepSeek R1 distill variants); resolved by simple averaging per canonical specification. Built 83x49 matrix. Benchmark names used as column headers. No joins needed; flat structure.",
    "n_models_raw": 83,
    "n_benchmarks_raw": 49
  },
  "data": {
    "n_models": 80,
    "n_benchmarks": 40,
    "missing_fraction": 0.5871875,
    "preprocessing": "Filtered benchmarks with <8 observed models (dropped 9 sparse benchmarks: AIME 2026, BigCodeBench, GDP-Val AA, IFBench, IMO 2025, MathVision, MRCR v2, SciCode, SimpleBench). Filtered models with <5 observed benchmarks in remaining set (dropped 3 models). Applied min-max normalization per benchmark to 0-100 scale to handle heterogeneous metrics (Elo, %, index). Imputed missing entries using iterative SVD at rank 5 (soft-impute style) with column-mean initialization, converging within 50 iterations.",
    "benchmarks_used": [
      "AA Intelligence Index",
      "AIME 2024",
      "AIME 2025",
      "ARC-AGI-1",
      "ARC-AGI-2",
      "Arena-Hard Auto",
      "BrowseComp",
      "BRUMO 2025",
      "Chatbot Arena Elo",
      "CMIMC 2025",
      "Codeforces Rating",
      "CritPt",
      "FrontierMath",
      "GPQA Diamond",
      "GSM8K",
      "HLE (Humanity's Last Exam)",
      "HMMT Feb 2025",
      "HMMT Nov 2025",
      "HumanEval",
      "IFEval",
      "LiveBench",
      "LiveCodeBench",
      "MATH-500",
      "MathArena Apex 2025",
      "MMLU",
      "MMLU-Pro",
      "MMMU",
      "MMMU-Pro",
      "MRCR v2",
      "OSWorld",
      "SimpleQA",
      "SMT 2025",
      "SWE-bench Pro",
      "SWE-bench Verified",
      "Tau-Bench Retail",
      "Tau-Bench Telecom",
      "Terminal-Bench 2.0",
      "Terminal-Bench 1.0",
      "USAMO 2025",
      "Video-MMU"
    ]
  },
  "rank_analysis": {
    "method": "SVD on min-max normalized, iteratively imputed (rank-5) matrix",
    "effective_rank": 2,
    "variance_explained_by_rank": 0.9059513439785501,
    "singular_values": [
      3506.5953939250157,
      802.9735395357571,
      719.8472852209298,
      649.7050102407466,
      546.4644351226729,
      116.97266445679163,
      115.86903407750937,
      98.7237454044814,
      87.89812805805722,
      83.19868011181869,
      80.38399646948947,
      73.72053420162943,
      72.29678329319903,
      66.76253665003314,
      62.930826679702825
    ],
    "justification": "First singular value captures 86% of variance (dominant general-ability factor). Rank 2 reaches 90.6%. Cross-validation on held-out observed entries selects rank 5 (MAE=12.89 on normalized scale). The matrix is strongly low-rank: ratio s1/s2 = 4.37. Effective rank reported as 2 by 90% threshold; CV-optimal rank is 5."
  },
  "benchmark_selection": {
    "method": "greedy_forward_selection",
    "selected_benchmarks": [
      "ARC-AGI-1",
      "BRUMO 2025",
      "OSWorld",
      "BrowseComp",
      "GSM8K",
      "Video-MMU",
      "MMMU-Pro",
      "Terminal-Bench 1.0"
    ],
    "n_selected": 8,
    "selection_criterion": "Minimize 5-fold cross-validation ridge regression MAE on imputed normalized matrix. At each step, add the benchmark that maximally reduces prediction error for all remaining benchmarks."
  },
  "prediction": {
    "method": "Ensemble of SVD completion (rank 3+5 average), ridge regression from selected subset, and KNN with inverse-distance weighting. Adaptive blending weights based on target benchmark observation density.",
    "overall_mae": 14.571955566039755,
    "per_benchmark_mae": {
      "AA Intelligence Index": 19.994309101725758,
      "AIME 2024": 9.270402352340167,
      "AIME 2025": 8.0370682361868,
      "ARC-AGI-2": 11.964306889841655,
      "Arena-Hard Auto": 6.3127446087151835,
      "Chatbot Arena Elo": 8.899390592064828,
      "CMIMC 2025": 19.006950841852138,
      "Codeforces Rating": 8.933072582356617,
      "CritPt": 20.112158531571655,
      "FrontierMath": 13.961449135498329,
      "GPQA Diamond": 7.381913000143024,
      "HLE (Humanity's Last Exam)": 12.889014545318195,
      "HMMT Feb 2025": 9.736158040691585,
      "HMMT Nov 2025": 14.369180552482561,
      "HumanEval": 6.5180681966576595,
      "IFEval": 6.6080841778678385,
      "LiveBench": 21.556539216128215,
      "LiveCodeBench": 8.483703837951985,
      "MATH-500": 6.391072764955829,
      "MathArena Apex 2025": 15.89459867612278,
      "MMLU": 7.031377596749092,
      "MMLU-Pro": 7.302826833845552,
      "MMMU": 10.012675644096879,
      "MRCR v2": 23.068395976371427,
      "SimpleQA": 11.261781849515662,
      "SMT 2025": 17.26674896539285,
      "SWE-bench Pro": 20.33877792318097,
      "SWE-bench Verified": 10.842682361769844,
      "Tau-Bench Retail": 13.247633651897539,
      "Tau-Bench Telecom": 16.758387681160507,
      "Terminal-Bench 2.0": 7.494375481659104,
      "USAMO 2025": 11.986606727255314
    },
    "evaluation_protocol": "Canonical reveal-k-per-model (k=5) for 12 eval models, with SVD+ridge+KNN ensemble. Self-evaluation used 5-fold CV on observed entries with ridge from 8 selected benchmarks.",
    "n_predictor_benchmarks": 8,
    "achieves_mae_under_5": false
  },
  "methodology_notes": "Key decisions: (1) Filtered sparse benchmarks/models before decomposition to improve SVD quality. (2) Min-max normalization to 0-100 handles mixed metrics (Elo ratings, percentages, index scores). (3) Iterative SVD imputation at rank 5 chosen by CV. (4) Greedy forward selection of 8 benchmarks spanning diverse categories (reasoning, math, agentic, multimodal, coding). (5) Canonical predictions use per-model ensemble: SVD completion provides global structure, ridge regression from 5 revealed benchmarks captures model-specific signal, KNN provides local smoothing. (6) Adaptive weighting gives more weight to ridge/KNN for well-observed target benchmarks and more weight to SVD for sparse targets. (7) The matrix is strongly dominated by a single general-ability factor (86% variance), consistent with a strong low-rank structure in LLM benchmarks."
}