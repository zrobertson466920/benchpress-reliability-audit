{
  "method": "Ridge regression (RidgeCV) from selected benchmark subset to each target",
  "overall_mae": 11.0248,
  "per_benchmark_mae": {
    "AIME 2024": 9.1084,
    "AIME 2025": 9.9994,
    "ARC-AGI-1": 13.512,
    "ARC-AGI-2": 7.9036,
    "Arena-Hard Auto": 15.3621,
    "BrowseComp": 13.4713,
    "BRUMO 2025": 9.2745,
    "Chatbot Arena Elo": 12.9389,
    "CMIMC 2025": 13.3848,
    "Codeforces Rating": 10.1969,
    "CritPt": 12.3317,
    "FrontierMath": 15.1406,
    "GPQA Diamond": 9.5429,
    "GSM8K": 12.3515,
    "HLE (Humanity's Last Exam)": 12.4751,
    "HMMT Feb 2025": 11.113,
    "HMMT Nov 2025": 21.0692,
    "HumanEval": 9.3353,
    "IFEval": 7.5901,
    "LiveBench": 18.834,
    "LiveCodeBench": 7.8595,
    "MATH-500": 7.801,
    "MathArena Apex 2025": 16.7506,
    "MMLU": 9.484,
    "MMLU-Pro": 8.3165,
    "MMMU": 8.5099,
    "MMMU-Pro": 22.7258,
    "OSWorld": 17.3634,
    "SimpleQA": 9.2955,
    "SMT 2025": 7.3005,
    "SWE-bench Pro": 16.8712,
    "SWE-bench Verified": 13.8044,
    "Tau-Bench Retail": 23.5277,
    "Terminal-Bench 2.0": 11.7437,
    "Terminal-Bench 1.0": 26.1801
  },
  "evaluation_protocol": "Leave-one-model-out cross-validation on observed entries, normalized 0-100 scale",
  "n_predictor_benchmarks": 7,
  "achieves_mae_under_5": false
}