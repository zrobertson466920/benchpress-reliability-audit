{
  "method": "Ridge regression (alpha=10) from selected benchmarks to targets",
  "overall_mae": 14.488,
  "per_benchmark_mae": {
    "AIME 2024": 7.3649,
    "ARC-AGI-1": 17.0034,
    "ARC-AGI-2": 19.7994,
    "Arena-Hard Auto": 26.2678,
    "BrowseComp": 29.5978,
    "BRUMO 2025": 9.9569,
    "Chatbot Arena Elo": 12.2994,
    "CMIMC 2025": 17.3784,
    "Codeforces Rating": 11.9616,
    "CritPt": 22.1159,
    "FrontierMath": 24.5911,
    "HLE (Humanity's Last Exam)": 15.4244,
    "HMMT Feb 2025": 8.4897,
    "HMMT Nov 2025": 8.095,
    "IFEval": 7.7274,
    "LiveBench": 12.1711,
    "MATH-500": 8.6609,
    "MathArena Apex 2025": 21.642,
    "MMLU": 9.1158,
    "MMLU-Pro": 8.4642,
    "MMMU": 21.174,
    "MMMU-Pro": 35.6682,
    "OSWorld": 20.0611,
    "SMT 2025": 10.3292,
    "SWE-bench Pro": 11.0081,
    "SWE-bench Verified": 16.3842,
    "Tau-Bench Retail": 12.3801,
    "Terminal-Bench 2.0": 11.6802,
    "Terminal-Bench 1.0": 24.1021
  },
  "evaluation_protocol": "Leave-one-model-out CV via hat-matrix on min-max normalized [0,100] scale",
  "n_predictor_benchmarks": 5,
  "achieves_mae_under_5": false,
  "n_predictions": 557
}